# #!/usr/bin/env python3
# import sys
# import json
# import time
# import random
# from pathlib import Path
#
# sys.path.append('..')
#
# from simple_pir import SimplePIRProtocol, SimplePIRConfig, SecurityLevel
#
# # è¦æµ‹è¯•çš„æ•°æ®é›†ï¼ˆä½ ç»™çš„ 6 ä¸ªï¼‰
# DATASETS = [
#     ("enron_1k",       Path("/root/siton-tmp/data/enron_1k.json")),
#     ("enron_5k",       Path("/root/siton-tmp/data/enron_5k.json")),
#     ("enron_10k",      Path("/root/siton-tmp/data/enron_10k.json")),
#     ("simplewiki_1k",  Path("/root/siton-tmp/data/simplewiki_1k.json")),
#     ("simplewiki_5k",  Path("/root/siton-tmp/data/simplewiki_5k.json")),
#     ("simplewiki_10k", Path("/root/siton-tmp/data/simplewiki_10k.json")),
# ]
#
# # æ¯ä¸ªæ•°æ®é›†åªæµ‹ 3 ä¸ª ID
# NUM_RETRIEVALS_PER_DATASET = 3
#
# RANDOM_SEED = 42
# random.seed(RANDOM_SEED)
#
#
# def load_documents(json_path: Path):
#     with json_path.open("r", encoding="utf-8") as f:
#         return json.load(f)
#
#
# def build_database_and_mapping(docs):
#     """
#     æ„å»ºï¼š
#       - database: PIR ç”¨çš„å†…å®¹åˆ—è¡¨
#       - docid_to_index: doc_id -> index
#     """
#     database = []
#     docid_to_index = {}
#
#     for idx, doc in enumerate(docs):
#         # doc_idï¼šå¦‚æœæ²¡ç»™ï¼Œå°±ç”¨ä¸‹æ ‡
#         doc_id = str(doc.get("id", "")).strip() or str(idx)
#
#         # å†…å®¹å­—æ®µï¼šä¼˜å…ˆ contentï¼Œå…¶æ¬¡ body/text/title
#         content = (
#             doc.get("content")
#             or doc.get("body")
#             or doc.get("text")
#             or doc.get("title")
#             or ""
#         )
#
#         database.append(content)
#         docid_to_index[doc_id] = idx
#
#     return database, docid_to_index
#
#
# def init_pir(database):
#     config = SimplePIRConfig(SecurityLevel.MEDIUM)
#     config.enable_preprocessing = True
#     pir = SimplePIRProtocol(database, config)
#     return pir
#
#
# def choose_doc_ids(docid_to_index, k: int):
#     """é€‰å‡ºè¦æµ‹è¯•çš„ doc_idï¼Œè¿™é‡Œç®€å•ç”¨éšæœºé€‰"""
#     all_ids = list(docid_to_index.keys())
#     if len(all_ids) <= k:
#         return all_ids
#     return random.sample(all_ids, k)
#
#
# def benchmark_dataset(dataset_name: str, json_path: Path):
#     docs = load_documents(json_path)
#     database, docid_to_index = build_database_and_mapping(docs)
#     pir = init_pir(database)
#
#     test_doc_ids = choose_doc_ids(docid_to_index, NUM_RETRIEVALS_PER_DATASET)
#
#     overall_times = []        # doc_id -> index + PIR
#     protocol_total_times = [] # PIR å†…éƒ¨ total_time
#
#     for doc_id in test_doc_ids:
#         # doc_id -> index
#         t0 = time.perf_counter()
#         index = docid_to_index[doc_id]
#         t1 = time.perf_counter()
#
#         # PIR åè®®
#         result = pir.retrieve_item(index)
#         t2 = time.perf_counter()
#
#         if not result["retrieval_successful"]:
#             continue
#
#         overall_times.append(t2 - t0)
#         protocol_total_times.append(result["performance_breakdown"]["total_time"])
#
#     if not overall_times:
#         print(f"{dataset_name}: no successful retrievals")
#         return
#
#     avg_overall = sum(overall_times) / len(overall_times)
#     avg_protocol = sum(protocol_total_times) / len(protocol_total_times)
#
#     # ğŸ‘‰ åªè¾“å‡ºä½ å…³å¿ƒçš„æ—¶é—´
#     print(
#         f"{dataset_name}: "
#         f"avg_overall_time={avg_overall:.6f}s, "
#         f"avg_protocol_time={avg_protocol:.6f}s, "
#         f"n={len(overall_times)}"
#     )
#
#
# def main():
#     for name, path in DATASETS:
#         benchmark_dataset(name, path)
#
#
# if __name__ == "__main__":
#     main()

#!/usr/bin/env python3
import sys
import json
import time
import random
from pathlib import Path

sys.path.append('..')

from simple_pir import SimplePIRProtocol, SimplePIRConfig, SecurityLevel

# è¦æµ‹è¯•çš„æ•°æ®é›†ï¼ˆæ–°å¢ msmarco_*ï¼‰
DATASETS = [
    ("enron_1k",       Path("/root/siton-tmp/data/enron_1k.json")),
    ("enron_5k",       Path("/root/siton-tmp/data/enron_5k.json")),
    ("enron_10k",      Path("/root/siton-tmp/data/enron_10k.json")),
    ("simplewiki_1k",  Path("/root/siton-tmp/data/simplewiki_1k.json")),
    ("simplewiki_5k",  Path("/root/siton-tmp/data/simplewiki_5k.json")),
    ("simplewiki_10k", Path("/root/siton-tmp/data/simplewiki_10k.json")),

    # âœ… æ–°å¢ MSMARCO
    ("msmarco_1k",     Path("/root/siton-tmp/data/msmarco_1k.json")),
    ("msmarco_5k",     Path("/root/siton-tmp/data/msmarco_5k.json")),
    ("msmarco_10k",    Path("/root/siton-tmp/data/msmarco_10k.json")),
]

# æ¯ä¸ªæ•°æ®é›†åªæµ‹ 3 ä¸ª ID
NUM_RETRIEVALS_PER_DATASET = 3

RANDOM_SEED = 42
random.seed(RANDOM_SEED)


def load_documents(json_path: Path):
    """
    è¿”å›ä¸€ä¸ª list[dict]ã€‚
    å…¼å®¹ä¸¤ç±»å¸¸è§ç»“æ„ï¼š
      1) ç›´æ¥æ˜¯ list
      2) dict åŒ…ä¸€å±‚ï¼Œä¾‹å¦‚ {"data":[...]} / {"docs":[...]} / {"documents":[...]} / {"items":[...]}
    """
    with json_path.open("r", encoding="utf-8") as f:
        data = json.load(f)

    if isinstance(data, dict):
        for k in ["data", "docs", "documents", "items", "passages"]:
            if k in data and isinstance(data[k], list):
                data = data[k]
                break

    if not isinstance(data, list):
        raise ValueError(f"Unexpected JSON format in {json_path}: root is {type(data)}")

    return data


def build_database_and_mapping(docs):
    """
    æ„å»ºï¼š
      - database: PIR ç”¨çš„å†…å®¹åˆ—è¡¨
      - docid_to_index: doc_id -> index
    """
    database = []
    docid_to_index = {}

    for idx, doc in enumerate(docs):
        if not isinstance(doc, dict):
            # å¦‚æœé‡åˆ°é dictï¼ˆæå°‘æ•°æƒ…å†µï¼‰ï¼Œè·³è¿‡æˆ–è½¬å­—ç¬¦ä¸²
            doc_id = str(idx)
            content = str(doc)
        else:
            # doc_idï¼šå¦‚æœæ²¡ç»™ï¼Œå°±ç”¨ä¸‹æ ‡
            doc_id = str(doc.get("id", "")).strip() or str(idx)

            # å†…å®¹å­—æ®µï¼šä¼˜å…ˆ contentï¼Œå…¶æ¬¡ body/text/title
            content = (
                doc.get("content")
                or doc.get("body")
                or doc.get("text")
                or doc.get("title")
                or ""
            )

        database.append(content)

        # å¦‚é‡åˆ°é‡å¤ doc_idï¼Œä¿ç•™ç¬¬ä¸€æ¬¡ï¼Œåç»­è·³è¿‡æ˜ å°„ï¼Œé¿å…è¦†ç›–
        if doc_id not in docid_to_index:
            docid_to_index[doc_id] = idx

    return database, docid_to_index


def init_pir(database):
    config = SimplePIRConfig(SecurityLevel.MEDIUM)
    config.enable_preprocessing = True
    pir = SimplePIRProtocol(database, config)
    return pir


def choose_doc_ids(docid_to_index, k: int):
    """é€‰å‡ºè¦æµ‹è¯•çš„ doc_idï¼Œè¿™é‡Œç®€å•ç”¨éšæœºé€‰"""
    all_ids = list(docid_to_index.keys())
    if len(all_ids) <= k:
        return all_ids
    return random.sample(all_ids, k)


def benchmark_dataset(dataset_name: str, json_path: Path):
    docs = load_documents(json_path)
    database, docid_to_index = build_database_and_mapping(docs)
    pir = init_pir(database)

    test_doc_ids = choose_doc_ids(docid_to_index, NUM_RETRIEVALS_PER_DATASET)

    overall_times = []        # doc_id -> index + PIR
    protocol_total_times = [] # PIR å†…éƒ¨ total_time

    for doc_id in test_doc_ids:
        # doc_id -> index
        t0 = time.perf_counter()
        index = docid_to_index[doc_id]
        t1 = time.perf_counter()

        # PIR åè®®
        result = pir.retrieve_item(index)
        t2 = time.perf_counter()

        if not result.get("retrieval_successful", False):
            continue

        overall_times.append(t2 - t0)

        perf = result.get("performance_breakdown", {})
        protocol_total_times.append(perf.get("total_time", 0.0))

    if not overall_times:
        print(f"{dataset_name}: no successful retrievals")
        return

    avg_overall = sum(overall_times) / len(overall_times)
    avg_protocol = sum(protocol_total_times) / len(protocol_total_times) if protocol_total_times else 0.0

    # ğŸ‘‰ åªè¾“å‡ºä½ å…³å¿ƒçš„æ—¶é—´
    print(
        f"{dataset_name}: "
        f"avg_overall_time={avg_overall:.6f}s, "
        f"avg_protocol_time={avg_protocol:.6f}s, "
        f"n={len(overall_times)}"
    )


def main():
    for name, path in DATASETS:
        benchmark_dataset(name, path)


if __name__ == "__main__":
    main()
